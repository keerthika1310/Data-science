# -*- coding: utf-8 -*-
"""Project2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_lp3d_o2_Mnfd8k6ogzwPaFXdJxh9O16

Upload the Datasets
"""

# Step 1: Upload the dataset
from google.colab import files
uploaded = files.upload()

"""Load the Datasets"""

# Step 2: Import required library and read the CSV
import pandas as pd

# Load the dataset
df = pd.read_csv("heart_failure_clinical_records_dataset.csv")

# Display first 5 rows
df.head()

"""Check the Missing values"""

# Overview of the dataset
df.info()

# Summary statistics
df.describe()

# Check for missing values
print("Missing values:\n", df.isnull().sum())

"""Data Exploration"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv("heart_failure_clinical_records_dataset.csv")

# Preview data
print(df.head())

# Shape of the dataset
print("Shape:", df.shape)

# Dataset info
print(df.info())

# Summary statistics
print(df.describe())

"""Missing Values"""

# Check for missing values
print("Missing values:\n", df.isnull().sum())

# Check for duplicate rows
print("Duplicate rows:", df.duplicated().sum())

"""Visualize the Features"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 5))
plt.hist(df['age'], bins=15, color='skyblue', edgecolor='black')
plt.title('Age Distribution')
plt.xlabel('Age')
plt.ylabel('Count')
plt.grid(True)
plt.show()

"""Box plot"""

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
sns.boxplot(x='DEATH_EVENT', y='age', data=df, palette='Set2')
plt.title('Box Plot of Age by DEATH_EVENT')
plt.xlabel('Death Event (0 = No, 1 = Yes)')
plt.ylabel('Age')
plt.show()

"""Target and Features"""

#Identify Target and Features
target = 'DEATH_EVENT'
features = df.columns.drop(target)
print("Features:", features)

"""Columns"""

import pandas as pd

# Load the heart failure dataset
df = pd.read_csv('heart_failure_clinical_records_dataset.csv')

# Print all column names
print("Columns:", df.columns.tolist())

"""Categorical Values"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Step 1: Load Dataset
df = pd.read_csv('heart_failure_clinical_records_dataset.csv')

# Step 2: One-Hot Encoding (if needed)
df_encoded = pd.get_dummies(df, drop_first=True)

# Step 3: Feature Scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df_encoded.drop('DEATH_EVENT', axis=1))
y = df_encoded['DEATH_EVENT']

# Step 4: Train-Test Split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Step 5: Model Building (Logistic Regression)
model = LogisticRegression()
model.fit(X_train, y_train)

# Step 6: Evaluation
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

"""Convert  to Dataframe and Encode"""

import pandas as pd
import numpy as np

# Example new input (replace values as needed)
new_input = {
    'age': 60,
    'anaemia': 0,
    'creatinine_phosphokinase': 250,
    'diabetes': 1,
    'ejection_fraction': 38,
    'high_blood_pressure': 1,
    'platelets': 250000,
    'serum_creatinine': 1.5,
    'serum_sodium': 137,
    'sex': 1,
    'smoking': 0,
    'time': 10
}
# Convert to DataFrame
new_df = pd.DataFrame([new_input])

# Scale using previously fitted scaler
new_scaled = scaler.transform(new_df)

# Predict
prediction = model.predict(new_scaled)

# Output
print("Predicted DEATH_EVENT (0 = survived, 1 = death):", prediction[0])

import joblib

# Save your trained model
joblib.dump(model, 'heart_failure_model.pkl')

# Save your scaler (if you used one)
joblib.dump(scaler, 'scaler.pkl')

# ðŸŽ¯ Predict the Final Grade
predicted_grade = model.predict(new_scaled) # Changed from new_input_scaled to new_scaled
print("ðŸŽ“ Predicted Final Grade (G3):", round(predicted_grade[0], 2))

!pip install gradio

# Install the latest version of gradio
!pip install --upgrade gradio

# Step 1: Import necessary libraries
import gradio as gr
import pandas as pd
import joblib
import numpy as np
# You might need PIL (Pillow) if you are dealing with image data in your function
# from PIL import Image

# Step 2: Load the saved model and scaler
try:
    model = joblib.load('heart_failure_model.pkl')
    scaler = joblib.load('scaler.pkl')
except FileNotFoundError:
    print("Model or scaler files not found. Please ensure 'heart_failure_model.pkl' and 'scaler.pkl' are in the correct directory.")
    # You might want to stop execution or handle this error appropriately
    # For now, we'll print a message and continue, but the app won't work without the files.


# Step 3: Define a prediction function that takes inputs and returns a prediction
# You might also want to return an image based on the prediction, if you have relevant images
def predict_heart_failure(age, anaemia, creatinine_phosphokinase, diabetes, ejection_fraction, high_blood_pressure, platelets, serum_creatinine, serum_sodium, sex, smoking, time):
    # Create a dictionary from the input values
    input_data = {
        'age': age,
        'anaemia': anaemia,
        'creatinine_phosphokinase': creatinine_phosphokinase,
        'diabetes': diabetes,
        'ejection_fraction': ejection_fraction,
        'high_blood_pressure': high_blood_pressure,
        'platelets': platelets,
        'serum_creatinine': serum_creatinine,
        'serum_sodium': serum_sodium,
        'sex': sex,
        'smoking': smoking,
        'time': time
    }

    # Convert the input dictionary to a DataFrame
    input_df = pd.DataFrame([input_data])

    try:
        # Scale the numerical features.
        # Ensure the column order matches the scaler's expected input order
        # You can get the original feature names from the scaler if needed: scaler.feature_names_in_
        # For simplicity, we assume the dictionary keys maintain the correct order for this dataset
        scaled_input = scaler.transform(input_df)
    except Exception as e:
        # More detailed error message for debugging scaling issues
        return f"Error during scaling: {e}. Ensure the input features match the scaler's expected features. Input columns: {input_df.columns.tolist()}"


    # Make the prediction using the loaded model
    try:
        prediction = model.predict(scaled_input)
        result_text = "Predicted outcome: Survived" if prediction[0] == 0 else "Predicted outcome: Death"

        # **Add logic to return an image based on the prediction**
        # You'll need to have image files available (e.g., 'survived.png', 'death.png')
        # and load them here or provide their paths.
        # Example (replace with your actual image loading logic):
        # from PIL import Image # Import Image if you uncomment this section
        # if prediction[0] == 0:
        #     result_image = Image.open('survived_image.png')
        # else:
        #     result_image = Image.open('death_image.png')

        # If you are returning multiple outputs (text and image), the function should return a tuple.
        # return result_text, result_image # Uncomment this line and the image loading logic above

        # For now, we are only returning the text result
        return result_text

    except Exception as e:
        return f"Error during prediction: {e}. Ensure the scaled input format is correct for the model."


# Step 4: Create Gradio interfaces
inputs = [
    gr.Number(label="Age"),
    gr.Radio([0, 1], label="Anaemia (0=No, 1=Yes)"),
    gr.Number(label="Creatinine Phosphokinase"),
    gr.Radio([0, 1], label="Diabetes (0=No, 1=Yes)"),
    gr.Number(label="Ejection Fraction"),
    gr.Radio([0, 1], label="High Blood Pressure (0=No, 1=Yes)"),
    gr.Number(label="Platelets"),
    gr.Number(label="Serum Creatinine"),
    gr.Number(label="Serum Sodium"),
    gr.Radio([0, 1], label="Sex (0=Female, 1=Male)"),
    gr.Radio([0, 1], label="Smoking (0=No, 1=Yes)"),
    gr.Number(label="Time (days)")
]

# Define the output components
# If you are returning both text and an image, define them here
outputs = [
    gr.Text(label="Prediction Result"),
    # gr.Image(label="Outcome Visualization") # Uncomment this if your function returns an image
]


# Step 5: Launch the Gradio interface
# Check if model and scaler were successfully loaded before launching
if 'model' in locals() and 'scaler' in locals() and model is not None and scaler is not None:
    try:
        # Set share=True to get a public link
        gr.Interface(fn=predict_heart_failure, inputs=inputs, outputs=outputs).launch(share=True)
    except Exception as e:
        print(f"Error launching Gradio interface: {e}")
else:
    print("Gradio interface not launched because model or scaler could not be loaded.")

# app.py

# Install necessary libraries if not already installed in the environment
# This is usually handled by the requirements.txt in deployment platforms like Hugging Face Spaces
# !pip install gradio pandas joblib numpy scikit-learn

# Step 1: Import necessary libraries
import gradio as gr
import pandas as pd
import joblib
import numpy as np
# Import Request from gradio.types - this might resolve the internal error after upgrading Gradio
try:
    from gradio.types import Request # Explicitly import Request
except ImportError:
    print("Warning: Could not import gradio.types.Request. Flagging might not work correctly in some Gradio versions.")
    Request = None # Define a dummy if import fails


# from PIL import Image # Uncomment if you plan to use images

# Step 2: Load the saved model and scaler
# In deployment, make sure these files ('heart_failure_model.pkl', 'scaler.pkl') are in the same directory as app.py
try:
    model = joblib.load('heart_failure_model.pkl')
    scaler = joblib.load('scaler.pkl')
    print("Model and scaler loaded successfully.")
except FileNotFoundError:
    print("Error: Model or scaler files not found.")
    # In a production app, you might want to raise an exception or exit here
    model = None
    scaler = None
except Exception as e:
    print(f"An error occurred loading model or scaler: {e}")
    model = None
    scaler = None


# Step 3: Define a prediction function that takes inputs and returns a prediction
# You might also want to return an image based on the prediction, if you have relevant images
def predict_heart_failure(age, anaemia, creatinine_phosphokinase, diabetes, ejection_fraction, high_blood_pressure, platelets, serum_creatinine, serum_sodium, sex, smoking, time):
    # Check if model and scaler were loaded
    if model is None or scaler is None:
        return "Error: Model or scaler failed to load. Cannot make prediction."

    # Create a dictionary from the input values
    input_data = {
        'age': age,
        'anaemia': anaemia,
        'creatinine_phosphokinase': creatinine_phosphokinase,
        'diabetes': diabetes,
        'ejection_fraction': ejection_fraction,
        'high_blood_pressure': high_blood_pressure,
        'platelets': platelets,
        'serum_creatinine': serum_creatinine,
        'serum_sodium': serum_sodium,
        'sex': sex,
        'smoking': smoking,
        'time': time
    }

    # Convert the input dictionary to a DataFrame
    input_df = pd.DataFrame([input_data])

    try:
        # Scale the numerical features.
        # Ensure the column order matches the scaler's expected input order
        # A robust way is to explicitly reindex or select columns based on the scaler's feature names
        # if scaler has feature_names_in_ attribute (available in newer scikit-learn)
        # or based on the columns used during scaler training.
        # For this specific dataset and assuming column order is consistent:
        scaled_input = scaler.transform(input_df)
    except Exception as e:
        # More detailed error message for debugging scaling issues
        return f"Error during scaling: {e}. Ensure the input features match the scaler's expected features. Input columns: {input_df.columns.tolist()}"


    # Make the prediction using the loaded model
    try:
        prediction = model.predict(scaled_input)
        result_text = "Predicted outcome: Survived" if prediction[0] == 0 else "Predicted outcome: Death"

        # **Optional: Add logic to return an image based on the prediction**
        # You'll need to have image files available (e.g., 'survived.png', 'death.png')
        # and load them here or provide their paths.
        # from PIL import Image # Import Image if you uncomment this section
        # if prediction[0] == 0:
        #     result_image = Image.open('survived_image.png')
        #     # Or return the path: result_image = 'survived_image.png'
        # else:
        #     result_image = Image.open('death_image.png')
        #     # Or return the path: result_image = 'death_image.png'

        # If you are returning multiple outputs (text and image), the function should return a tuple.
        # return result_text, result_image # Uncomment this line and the image loading logic above

        # For now, we are only returning the text result
        return result_text

    except Exception as e:
        return f"Error during prediction: {e}. Ensure the scaled input format is correct for the model."


# Step 4: Create Gradio interfaces
inputs = [
    gr.Number(label="Age"),
    gr.Radio([0, 1], label="Anaemia (0=No, 1=Yes)"),
    gr.Number(label="Creatinine Phosphokinase"),
    gr.Radio([0, 1], label="Diabetes (0=No, 1=Yes)"),
    gr.Number(label="Ejection Fraction"),
    gr.Radio([0, 1], label="High Blood Pressure (0=No, 1=Yes)"),
    gr.Number(label="Platelets"),
    gr.Number(label="Serum Creatinine"),
    gr.Number(label="Serum Sodium"),
    gr.Radio([0, 1], label="Sex (0=Female, 1=Male)"),
    gr.Radio([0, 1], label="Smoking (0=No, 1=Yes)"),
    gr.Number(label="Time (days)")
]

# Define the output components
outputs = [
    gr.Text(label="Prediction Result"),
    # gr.Image(label="Outcome Visualization") # Uncomment this if your function returns an image
]


# Step 5: Launch the Gradio interface
# In deployment environments like Hugging Face Spaces, Gradio automatically handles the server.
# The `if __name__ == "__main__":` block is standard practice for making the script runnable.
if __name__ == "__main__":
    if model is not None and scaler is not None:
         # Set launch(share=True) to False for production deployment on platforms like Spaces
         # Gradio on Spaces automatically handles public access.
         # Disable flagging temporarily if the error persists after importing Request
         gr.Interface(fn=predict_heart_failure, inputs=inputs, outputs=outputs,
                      title="Heart Failure Prediction", # Add a title
                      description="Predict the likelihood of a heart failure event based on clinical data.", # Add a description
                      allow_flagging='never' # Added this line to disable flagging
                     ).launch() # No need for share=True on Hugging Face Spaces
    else:
        print("Gradio interface not launched because model or scaler could not be loaded.")
        # In a real app, you might want to return an error page or message